{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rN52qdMtZ1Z5"},"outputs":[],"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup as bs\n","from time import sleep\n","import re\n"]},{"cell_type":"markdown","metadata":{"id":"qMKkWxRCaJvS"},"source":["Load web pages links file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSwq1DDgZ-2s"},"outputs":[],"source":["df = pd.read_csv('furniture stores pages.csv', names=['Links'], skiprows=1)\n","links = df['Links'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DrLLUAGSaiXS"},"outputs":[],"source":["# RegEx pattern to match 'product' with any words and slashes in front or back\n","pattern = re.compile(r'[-_\\w/]*product[-_\\w/]*')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-4dCEAfamnZ"},"outputs":[],"source":["pages_crawled = 0\n","data = []\n","number_of_pages = df.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12487,"status":"ok","timestamp":1698415038179,"user":{"displayName":"Dimitar Georgiev","userId":"12201600207448994377"},"user_tz":-180},"id":"JTpN8CEaaz6x","outputId":"5785238a-de7c-4f28-9c0a-1d786c9a35d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Crawled page 1: https://www.factorybuys.com.au/products/euro-top-mattress-king\n","Crawled page 2: https://dunlin.com.au/products/beadlight-cirrus\n","Crawled page 3: https://themodern.net.au/products/hamar-plant-stand-ash\n"]}],"source":["for url in links:\n","    if pages_crawled >= number_of_pages:\n","        break  # Stop crawling\n","\n","    try:\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","            page_html = response.text\n","            page_bs = bs(page_html, 'html.parser')\n","\n","            # Find elements with a class attribute that matches the pattern\n","            target_tags = page_bs.find_all(lambda tag: tag.name in ['h1', 'h2'] and tag.has_attr('class') and pattern.search(' '.join(tag['class'])))\n","\n","            # Extract the text content of the found elements\n","            for tag in target_tags:\n","                element_text = tag.get_text()\n","                #data.extend(element_text)\n","                element_strip = element_text.strip()\n","\n","                # TODO: check string for proper results\n","                if \"\".__eq__(element_strip) or len(element_strip) > 50:\n","                  data.append([element_strip, 'text', url])\n","                else:\n","                  data.append([element_strip, 'product', url])\n","\n","            # Increment counter\n","            pages_crawled += 1\n","\n","            print(f'Crawled page {pages_crawled}: {url}')\n","\n","        else:\n","            print(f'Failed to crawl {url}. Status code: {response.status_code}')\n","\n","    except Exception as e:\n","        print(f'An error occurred while crawling {url}: {str(e)}')\n","\n","    sleep(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2lxRJTXrbGLh"},"outputs":[],"source":["# Create a DataFrame from the collected data\n","df = pd.DataFrame(data, columns=['product', 'match', 'url'])\n","\n","# Save the data to csv file\n","extracted_data = 'products_data.csv'\n","df.to_csv(extracted_data, index=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPAZNJxjjKBx2qETXE6d8QC","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
